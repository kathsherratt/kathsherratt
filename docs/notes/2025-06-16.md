Monday, 16th June

## "What I learned in 43yrs modelling"

Graham Medley, LSHTM

<details> <summary>What-where-when</summary>
	
- ID modelling short course
- LSHTM/UKHSA run training course
- celebrating 25 years
  - week of evening lectures reflecting on the field
</details>

<details> <summary>Highlights</summary>

- scientific
  - emergence of "public health engineering" i.e. applied modelling
  - full relativism re model quality - no objective standard; only solution is multiple models
  - what we normally call "evidence" is retrospective/observational - modelling doesn't fit this ?
- sociologic
  - comp sci training = triple modular redundancy principle = multiple models
  - first outbreak response experience = HIV work
  - joy of modelling as exploration

</details>
	
<details><summary>Notes</summary>

  - Key is diff between modelling vs use of modelling

	- First ID modelling course 1980s; James Noakes & Medley at Imperial

	- Introducing the archetypal model: SIR

		- All modelling is complicating the SIR: either -

			- Complicating the infection process: we do not infect equally; R0

			- Complicating immunity: not lifelong (SIR) nor immediate (SIS)

			- M/M/R diseases are closest to this model

		- Complicating immunity:

			- Duration of protection: waning immunity

			- Degree of protection: partial immunity (sigma)

				- 2004 work on reinfection threshold

					- @Infection, reinfection, and vaccination under suboptimal immune protection: epidemiological perspectives

					- Relevance for vaccination

						- R.eff only <1 if R0 (without vaccine) is < 1/sigma

						- Most enjoyment in modelling from using models to generate alternative explanations

							- "counterintuitive" finding / exploring possibilities

							- (Medley not a mathematician: has "maths envy")

	- Applications

		- SPI-M from 2012; met 2-3x a year; discussing possibilities of epi/pandemic

			- Zero policy interest in modelling in 1983

		- SPI-M-O

			- Challenges

				- Unequal resources: Groups had different data, computing power

				- Multiple models: at least 3 models for each question

					- Medley - half biology, half comp sci: triple modular redundancy principle

					- this "really worked"

						- Gave an idea of "the modelling"

						- Gave policy a consensus of "the modelling evidence"

			- Consensus

				- "making modelling less wrong"

				- "Evidence"

					- Evidence popularly seen as retrospective, testing hypotheses

					- What is evidence before the event? i.e. what we do know. This is not research. Modelling evidence is about the future

					- eg: Social bubble size (idea from new zealand); modelling showed importance of fidelity to group, not size

				- Communicating

					- Secretariat and policy co-chair critical

					- Uncertainty - perception from policy that uncertainty is "ignorance" (- "why don't you know")

						- Need proper guidance on communicating uncertainty

						- eg: Medium term projections, rainbow plot showing multiple models: very useful to policymakers for quick view

			- Decision space

				- "You cannot make policy neutral models"

					- all models have implicit policy decisions

					- to make a model useful, need a virtuous cycle of policy interaction / model feedback, to ensure evidence matches the question

					- Covid SPI-M underused for policy strategy initially (one way, frustration)

					- Changed when policy became receptive to modelling & open to talking ("if you find a policy person receptive, never let them go, they are like gold dust")

			- Wrong but useful

				- Extent of Correctness up to you

				- Extent of Usefulness is up to the user

					- Modellers: useful if you learn something; somebody else: let them decide

					- history littered with bad, useful models & good, useless models

			- Where is modelling going?

				- Code: modelling becoming easier; recent question about a model produced in 1993, able to reproduce based on the paper, 80x faster

				- From "science" to "Public health engineering"

					- Can't build a bridge without a model

					- Same in public health? noone would introduce a vaccine programme without modelling

				- Need to address the big public health questions: inequality

				- Prediction accuracy: Can never model vaccine programming in the same way as a bridge

					- Only way to address this is to use multiple models

						- Now so much easier to model

						- Q: models so based on assumptions, combination?

						- Q: prediction accuracy vs learning?

					- Accreditation for modelling standards?

						- Richard White: modelling was the wild west 25y ago; hasn't changed that much

						- GM: covid showed this starkly

							- eg UK gov using KPMG model

							- 25y ago we didn't code, but papers had equations

							- computational vs mathematical

							- authority based on reputation - used eg Richard White

	- Q&A

		- History of modelling: arose several times

		- What's the top quality of a "good" model?

			- No scale for good model

		- Impact of AI?

			- Richard: modelling = modelling a process (AI is modelling an outcome)

		- Given policy turnover, would same problems recur?

			- Much better when people from intelligence joined - used to dealing with uncertainty

		- Paul Fine: all models wrong - we ignore that part of the box quote - but this has downsides; modelling community not self critical

	- Post session chat

		- Graham's experiences shaped by early work on HIV response

		- Only saw Hine report after a few months into chairing spi-m-o: a colleague recommended

    - "aim in covid was not to let reputation of epi modelling be harmed"
      
</details>
